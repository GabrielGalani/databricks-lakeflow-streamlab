# databricks-lakeflow-streamlab

Lakeflow StreamLab demonstrates an end-to-end streaming data pipeline using Databricks Lakeflow (Delta Live Tables), focusing on schema evolution, data quality, and real-time analytics.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streaming Generatorâ”‚
â”‚ (PySpark)          â”‚
â”‚ - dados vÃ¡lidos    â”‚
â”‚ - dados invÃ¡lidos  â”‚
â”‚ - schema changes   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BRONZE (DLT)       â”‚
â”‚ - ingestÃ£o raw     â”‚
â”‚ - schema flexÃ­vel  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SILVER (DLT)       â”‚
â”‚ - validaÃ§Ã£o        â”‚
â”‚ - expectations     â”‚
â”‚ - limpeza          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GOLD (DLT)         â”‚
â”‚ - agregaÃ§Ãµes       â”‚
â”‚ - mÃ©tricas         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Databricks SQL     â”‚
â”‚ - queries          â”‚
â”‚ - dashboards       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


# Data Pipeline: E-commerce Medallion Architecture (DLT & Streaming)

Este projeto implementa um pipeline de dados ponta a ponta utilizando **Delta Live Tables (DLT)** no Databricks. A arquitetura segue o padrÃ£o **Medallion (Bronze, Silver)**, processando dados de e-commerce em tempo real via **Streaming** e tratando mudanÃ§as de estado atravÃ©s de **CDC (Change Data Capture)**.

## ğŸš€ Tecnologias Utilizadas

* **Databricks Delta Live Tables (DLT)**: Para orquestraÃ§Ã£o e governanÃ§a do pipeline.
* **Spark Structured Streaming**: Para processamento de dados em tempo real.
* **Unity Catalog**: Gerenciamento de governanÃ§a, esquemas e permissÃµes.
* **Python & SQL**: Linguagens utilizadas no desenvolvimento das transformaÃ§Ãµes.

---

## ğŸ—ï¸ Arquitetura do Pipeline

O pipeline estÃ¡ dividido em camadas para garantir a qualidade e a confiabilidade dos dados:

1.  **Bronze**: IngestÃ£o de dados brutos (*raw*) mantendo a fidelidade Ã  fonte original.
2.  **CDC**: Captura de mudanÃ§as para entidades dinÃ¢micas (Clientes, Produtos, Vendedores).
3.  **Silver**: Limpeza, deduplicaÃ§Ã£o e enriquecimento dos dados.

### Fluxo Visual do Pipeline
> [!TIP]
> Abaixo estÃ£o as representaÃ§Ãµes visuais do fluxo de dados e da linhagem das tabelas.

![Pipeline de Dados - VisÃ£o Geral](caminho_da_sua_imagem_1.png)
*Legenda: Fluxo de ingestÃ£o da camada Bronze para a Silver.*

![Linhagem DLT](caminho_da_sua_imagem_2.png)
*Legenda: Grafo de dependÃªncias gerado pelo Delta Live Tables.*

---

## ğŸ“‚ Estrutura de Arquivos

```text
src/
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ bronze/          # Scripts de ingestÃ£o inicial (Raw)
â”‚   â”œâ”€â”€ cdc/             # LÃ³gica de Change Data Capture
â”‚   â””â”€â”€ silver/          # TransformaÃ§Ãµes, joins e limpeza
â”œâ”€â”€ setup/               # Scripts de infraestrutura (Schemas, UC, Volumes)
â””â”€â”€ utils/               # Gerador de dados sintÃ©ticos para teste
